{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethy17/CPE019-CPE32S9/blob/main/Hands_on_Activity_6_2_Training_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Kristian Marc P. Dayrit"
      ],
      "metadata": {
        "id": "-nuYG07Hyzlo"
      },
      "id": "-nuYG07Hyzlo"
    },
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "undefined-inventory",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "undefined-inventory",
        "outputId": "34b9d1a6-d1a8-4e6b-c027-3826d6c3ce8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "638               7                      97              76              32   \n",
              "44                7                     159              64               0   \n",
              "207               5                     162             104               0   \n",
              "509               8                     120              78               0   \n",
              "692               2                     121              70              32   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "638       91  40.9              0.871   32             1  \n",
              "44         0  27.4              0.294   40             0  \n",
              "207        0  37.7              0.151   52             1  \n",
              "509        0  25.0              0.409   64             0  \n",
              "692       95  39.1              0.886   23             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ee6ca14-d967-4e18-96af-cbdd287ae4ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>7</td>\n",
              "      <td>97</td>\n",
              "      <td>76</td>\n",
              "      <td>32</td>\n",
              "      <td>91</td>\n",
              "      <td>40.9</td>\n",
              "      <td>0.871</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>7</td>\n",
              "      <td>159</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.4</td>\n",
              "      <td>0.294</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>5</td>\n",
              "      <td>162</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.7</td>\n",
              "      <td>0.151</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>8</td>\n",
              "      <td>120</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.409</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>2</td>\n",
              "      <td>121</td>\n",
              "      <td>70</td>\n",
              "      <td>32</td>\n",
              "      <td>95</td>\n",
              "      <td>39.1</td>\n",
              "      <td>0.886</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ee6ca14-d967-4e18-96af-cbdd287ae4ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ee6ca14-d967-4e18-96af-cbdd287ae4ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ee6ca14-d967-4e18-96af-cbdd287ae4ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b1c41c5-8ee4-4aa8-ab16-b422944df18c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b1c41c5-8ee4-4aa8-ab16-b422944df18c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b1c41c5-8ee4-4aa8-ab16-b422944df18c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 97,\n        \"max\": 162,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          159,\n          121,\n          162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 64,\n        \"max\": 104,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          64,\n          70,\n          104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 0,\n        \"max\": 32,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 0,\n        \"max\": 95,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          91,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.277843087069136,\n        \"min\": 25.0,\n        \"max\": 40.9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          27.4,\n          39.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3378945101655249,\n        \"min\": 0.151,\n        \"max\": 0.886,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.294,\n          0.886\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 23,\n        \"max\": 64,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          40,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "systematic-motorcycle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "systematic-motorcycle",
        "outputId": "e7f0f55e-c718-487b-a63a-037fff4177ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "acceptable-equity",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "acceptable-equity",
        "outputId": "90bb2c30-a63d-4030-d192-f4af4b5479c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "correct-kingdom",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "correct-kingdom",
        "outputId": "69b401a5-3b6d-4164-d1e4-e3ea2669a868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "happy-prompt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "happy-prompt",
        "outputId": "54ae4dd1-effa-4622-ed69-527aafefc38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 18ms/step - loss: 0.8077 - accuracy: 0.4983 - val_loss: 0.8151 - val_accuracy: 0.5156\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7831 - accuracy: 0.5347 - val_loss: 0.7892 - val_accuracy: 0.5469\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7619 - accuracy: 0.5625 - val_loss: 0.7670 - val_accuracy: 0.5677\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7435 - accuracy: 0.5903 - val_loss: 0.7474 - val_accuracy: 0.5833\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7274 - accuracy: 0.6059 - val_loss: 0.7303 - val_accuracy: 0.5990\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7133 - accuracy: 0.6181 - val_loss: 0.7152 - val_accuracy: 0.6094\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7004 - accuracy: 0.6302 - val_loss: 0.7017 - val_accuracy: 0.6042\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6889 - accuracy: 0.6493 - val_loss: 0.6896 - val_accuracy: 0.6250\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.6562 - val_loss: 0.6787 - val_accuracy: 0.6302\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6691 - accuracy: 0.6632 - val_loss: 0.6688 - val_accuracy: 0.6406\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.6684 - val_loss: 0.6597 - val_accuracy: 0.6615\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.6736 - val_loss: 0.6513 - val_accuracy: 0.6562\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6449 - accuracy: 0.6806 - val_loss: 0.6435 - val_accuracy: 0.6562\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6380 - accuracy: 0.6944 - val_loss: 0.6363 - val_accuracy: 0.6562\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.6979 - val_loss: 0.6297 - val_accuracy: 0.6667\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6252 - accuracy: 0.7031 - val_loss: 0.6235 - val_accuracy: 0.6719\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6195 - accuracy: 0.7014 - val_loss: 0.6177 - val_accuracy: 0.6719\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6139 - accuracy: 0.7049 - val_loss: 0.6121 - val_accuracy: 0.6771\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.7118 - val_loss: 0.6070 - val_accuracy: 0.6771\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6037 - accuracy: 0.7118 - val_loss: 0.6020 - val_accuracy: 0.6771\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5990 - accuracy: 0.7083 - val_loss: 0.5974 - val_accuracy: 0.6823\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.7118 - val_loss: 0.5930 - val_accuracy: 0.6875\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.7101 - val_loss: 0.5888 - val_accuracy: 0.6979\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.7118 - val_loss: 0.5849 - val_accuracy: 0.7031\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5823 - accuracy: 0.7153 - val_loss: 0.5813 - val_accuracy: 0.7083\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.7170 - val_loss: 0.5778 - val_accuracy: 0.7083\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5752 - accuracy: 0.7205 - val_loss: 0.5745 - val_accuracy: 0.7083\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5718 - accuracy: 0.7222 - val_loss: 0.5714 - val_accuracy: 0.7083\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5688 - accuracy: 0.7240 - val_loss: 0.5684 - val_accuracy: 0.7083\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5657 - accuracy: 0.7240 - val_loss: 0.5655 - val_accuracy: 0.7083\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5628 - accuracy: 0.7222 - val_loss: 0.5628 - val_accuracy: 0.7083\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5601 - accuracy: 0.7240 - val_loss: 0.5602 - val_accuracy: 0.7031\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5572 - accuracy: 0.7240 - val_loss: 0.5578 - val_accuracy: 0.7135\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5545 - accuracy: 0.7240 - val_loss: 0.5554 - val_accuracy: 0.7135\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5519 - accuracy: 0.7274 - val_loss: 0.5532 - val_accuracy: 0.7188\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5493 - accuracy: 0.7240 - val_loss: 0.5510 - val_accuracy: 0.7188\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5468 - accuracy: 0.7274 - val_loss: 0.5489 - val_accuracy: 0.7240\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5444 - accuracy: 0.7309 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5420 - accuracy: 0.7292 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5397 - accuracy: 0.7326 - val_loss: 0.5429 - val_accuracy: 0.7240\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5373 - accuracy: 0.7309 - val_loss: 0.5411 - val_accuracy: 0.7240\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5351 - accuracy: 0.7344 - val_loss: 0.5393 - val_accuracy: 0.7188\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5330 - accuracy: 0.7344 - val_loss: 0.5376 - val_accuracy: 0.7240\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5308 - accuracy: 0.7326 - val_loss: 0.5360 - val_accuracy: 0.7240\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5288 - accuracy: 0.7344 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7326 - val_loss: 0.5329 - val_accuracy: 0.7292\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5249 - accuracy: 0.7309 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5230 - accuracy: 0.7344 - val_loss: 0.5301 - val_accuracy: 0.7240\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7361 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.7344 - val_loss: 0.5275 - val_accuracy: 0.7240\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7361 - val_loss: 0.5263 - val_accuracy: 0.7240\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5160 - accuracy: 0.7361 - val_loss: 0.5251 - val_accuracy: 0.7292\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7361 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5126 - accuracy: 0.7378 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5110 - accuracy: 0.7396 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7413 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5077 - accuracy: 0.7413 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5060 - accuracy: 0.7483 - val_loss: 0.5192 - val_accuracy: 0.7240\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5044 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7240\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.7535 - val_loss: 0.5175 - val_accuracy: 0.7240\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.7535 - val_loss: 0.5167 - val_accuracy: 0.7240\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7535 - val_loss: 0.5160 - val_accuracy: 0.7240\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.7535 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4968 - accuracy: 0.7569 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4954 - accuracy: 0.7569 - val_loss: 0.5138 - val_accuracy: 0.7292\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4940 - accuracy: 0.7622 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4927 - accuracy: 0.7587 - val_loss: 0.5124 - val_accuracy: 0.7292\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4914 - accuracy: 0.7622 - val_loss: 0.5118 - val_accuracy: 0.7292\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4901 - accuracy: 0.7604 - val_loss: 0.5111 - val_accuracy: 0.7292\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.5105 - val_accuracy: 0.7240\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4877 - accuracy: 0.7691 - val_loss: 0.5100 - val_accuracy: 0.7240\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4868 - accuracy: 0.7691 - val_loss: 0.5095 - val_accuracy: 0.7240\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4855 - accuracy: 0.7691 - val_loss: 0.5089 - val_accuracy: 0.7240\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4845 - accuracy: 0.7674 - val_loss: 0.5085 - val_accuracy: 0.7292\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.7674 - val_loss: 0.5080 - val_accuracy: 0.7292\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4824 - accuracy: 0.7691 - val_loss: 0.5075 - val_accuracy: 0.7292\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4815 - accuracy: 0.7674 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4806 - accuracy: 0.7691 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4777 - accuracy: 0.7708 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4769 - accuracy: 0.7726 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4761 - accuracy: 0.7708 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7708 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7726 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7708 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7708 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7726 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7743 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7760 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7743 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4544 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4532 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4525 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4523 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4513 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4511 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4491 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4484 - accuracy: 0.7795 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7865 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4441 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4436 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4391 - accuracy: 0.7934 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "unsigned-nevada",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "unsigned-nevada",
        "outputId": "a8081128-809f-4f20-f27e-5ecc7a255d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)\n",
        "y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "tough-catering",
      "metadata": {
        "id": "tough-catering",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9c117d0d-7ef8-4377-fbfa-e2390fc29986"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "combined-zimbabwe",
      "metadata": {
        "id": "combined-zimbabwe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5f8e1934-f0f5-4420-a423-a70a51e6399d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.58750594],\n",
              "       [0.6804376 ],\n",
              "       [0.28522703],\n",
              "       [0.23143695],\n",
              "       [0.16816118],\n",
              "       [0.52589536],\n",
              "       [0.02137552],\n",
              "       [0.32752517],\n",
              "       [0.9220571 ],\n",
              "       [0.22163317]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "eleven-nebraska",
      "metadata": {
        "id": "eleven-nebraska",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "outputId": "63ecd6ff-e207-46cb-d339-e12ee333f05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.750\n",
            "roc-auc is 0.813\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "hidden-physics",
      "metadata": {
        "id": "hidden-physics",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f96e52a4-fcc7-4a7b-eada-8eb42352bf1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "banned-spider",
      "metadata": {
        "id": "banned-spider",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "404121bb-d5d8-414c-8f8a-fa8f175b0fd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cc99936ae00>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "My interpretation about the result is that as the amount of epoch increases the lower the train loss and the stable the validation loss becomes and it indicates that the model is learning the data patterns effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a model with two hidden layers, each with 6 nodes\n",
        "#Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "\n",
        "model  = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "w7e6x9ZNJOK7"
      },
      "id": "w7e6x9ZNJOK7",
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use a learning rate of .003 and train for 1500 epochs\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "o7EneeODKqfs",
        "outputId": "1231046b-8c1f-4e25-ad99-fdf7b9700f01"
      },
      "id": "o7EneeODKqfs",
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 2s 31ms/step - loss: 0.7666 - accuracy: 0.3785 - val_loss: 0.7493 - val_accuracy: 0.4062\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.7413 - accuracy: 0.4149 - val_loss: 0.7293 - val_accuracy: 0.4531\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.7216 - accuracy: 0.4549 - val_loss: 0.7141 - val_accuracy: 0.4688\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7059 - accuracy: 0.4983 - val_loss: 0.7018 - val_accuracy: 0.5000\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6929 - accuracy: 0.5486 - val_loss: 0.6917 - val_accuracy: 0.5052\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6822 - accuracy: 0.5903 - val_loss: 0.6831 - val_accuracy: 0.5260\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6729 - accuracy: 0.5920 - val_loss: 0.6754 - val_accuracy: 0.5417\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6645 - accuracy: 0.6007 - val_loss: 0.6685 - val_accuracy: 0.5885\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6568 - accuracy: 0.6042 - val_loss: 0.6624 - val_accuracy: 0.5990\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6496 - accuracy: 0.6146 - val_loss: 0.6569 - val_accuracy: 0.6198\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6432 - accuracy: 0.6198 - val_loss: 0.6518 - val_accuracy: 0.6250\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6374 - accuracy: 0.6337 - val_loss: 0.6471 - val_accuracy: 0.6302\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6320 - accuracy: 0.6389 - val_loss: 0.6429 - val_accuracy: 0.6354\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6269 - accuracy: 0.6458 - val_loss: 0.6389 - val_accuracy: 0.6354\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6221 - accuracy: 0.6476 - val_loss: 0.6349 - val_accuracy: 0.6406\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6175 - accuracy: 0.6545 - val_loss: 0.6310 - val_accuracy: 0.6406\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6132 - accuracy: 0.6545 - val_loss: 0.6273 - val_accuracy: 0.6458\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6088 - accuracy: 0.6545 - val_loss: 0.6236 - val_accuracy: 0.6510\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6047 - accuracy: 0.6545 - val_loss: 0.6201 - val_accuracy: 0.6562\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6007 - accuracy: 0.6545 - val_loss: 0.6167 - val_accuracy: 0.6562\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5968 - accuracy: 0.6562 - val_loss: 0.6134 - val_accuracy: 0.6562\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5929 - accuracy: 0.6597 - val_loss: 0.6102 - val_accuracy: 0.6510\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5891 - accuracy: 0.6597 - val_loss: 0.6071 - val_accuracy: 0.6510\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5853 - accuracy: 0.6632 - val_loss: 0.6041 - val_accuracy: 0.6510\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5817 - accuracy: 0.6649 - val_loss: 0.6011 - val_accuracy: 0.6562\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5782 - accuracy: 0.6649 - val_loss: 0.5982 - val_accuracy: 0.6562\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5747 - accuracy: 0.6684 - val_loss: 0.5954 - val_accuracy: 0.6615\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.6684 - val_loss: 0.5927 - val_accuracy: 0.6562\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5677 - accuracy: 0.6684 - val_loss: 0.5902 - val_accuracy: 0.6615\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.6701 - val_loss: 0.5878 - val_accuracy: 0.6615\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5608 - accuracy: 0.6701 - val_loss: 0.5854 - val_accuracy: 0.6667\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5573 - accuracy: 0.6771 - val_loss: 0.5830 - val_accuracy: 0.6771\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5540 - accuracy: 0.6753 - val_loss: 0.5807 - val_accuracy: 0.6719\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5507 - accuracy: 0.6753 - val_loss: 0.5784 - val_accuracy: 0.6719\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.6753 - val_loss: 0.5762 - val_accuracy: 0.6719\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.6823 - val_loss: 0.5740 - val_accuracy: 0.6823\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5409 - accuracy: 0.6840 - val_loss: 0.5720 - val_accuracy: 0.6823\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.6875 - val_loss: 0.5699 - val_accuracy: 0.6771\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.6875 - val_loss: 0.5680 - val_accuracy: 0.6771\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5315 - accuracy: 0.6858 - val_loss: 0.5662 - val_accuracy: 0.6719\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5286 - accuracy: 0.6892 - val_loss: 0.5645 - val_accuracy: 0.6719\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.6892 - val_loss: 0.5628 - val_accuracy: 0.6771\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.6875 - val_loss: 0.5612 - val_accuracy: 0.6823\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5202 - accuracy: 0.6944 - val_loss: 0.5597 - val_accuracy: 0.6823\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7014 - val_loss: 0.5583 - val_accuracy: 0.6927\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.6997 - val_loss: 0.5570 - val_accuracy: 0.6927\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.7049 - val_loss: 0.5558 - val_accuracy: 0.6875\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.7066 - val_loss: 0.5545 - val_accuracy: 0.6823\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7118 - val_loss: 0.5534 - val_accuracy: 0.6823\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.7118 - val_loss: 0.5523 - val_accuracy: 0.6771\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7170 - val_loss: 0.5513 - val_accuracy: 0.6771\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7170 - val_loss: 0.5504 - val_accuracy: 0.6771\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7205 - val_loss: 0.5495 - val_accuracy: 0.6719\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7205 - val_loss: 0.5487 - val_accuracy: 0.6719\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7257 - val_loss: 0.5481 - val_accuracy: 0.6719\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7257 - val_loss: 0.5475 - val_accuracy: 0.6719\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7257 - val_loss: 0.5469 - val_accuracy: 0.6719\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7274 - val_loss: 0.5463 - val_accuracy: 0.6823\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7274 - val_loss: 0.5458 - val_accuracy: 0.6875\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7274 - val_loss: 0.5453 - val_accuracy: 0.6875\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7326 - val_loss: 0.5449 - val_accuracy: 0.6875\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7326 - val_loss: 0.5444 - val_accuracy: 0.6927\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7326 - val_loss: 0.5441 - val_accuracy: 0.6927\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7326 - val_loss: 0.5438 - val_accuracy: 0.6927\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7326 - val_loss: 0.5436 - val_accuracy: 0.6979\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7344 - val_loss: 0.5433 - val_accuracy: 0.6979\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7378 - val_loss: 0.5431 - val_accuracy: 0.6979\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7396 - val_loss: 0.5429 - val_accuracy: 0.7031\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7448 - val_loss: 0.5427 - val_accuracy: 0.7031\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7483 - val_loss: 0.5426 - val_accuracy: 0.7031\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7483 - val_loss: 0.5425 - val_accuracy: 0.6979\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7483 - val_loss: 0.5423 - val_accuracy: 0.7031\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4743 - accuracy: 0.7483 - val_loss: 0.5422 - val_accuracy: 0.7031\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7500 - val_loss: 0.5420 - val_accuracy: 0.7031\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7656 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7795 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7344\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.5419 - val_accuracy: 0.7292\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.5420 - val_accuracy: 0.7292\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5420 - val_accuracy: 0.7292\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.5420 - val_accuracy: 0.7344\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7899 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7899 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7899 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.5423 - val_accuracy: 0.7292\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7865 - val_loss: 0.5423 - val_accuracy: 0.7240\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7865 - val_loss: 0.5424 - val_accuracy: 0.7292\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7899 - val_loss: 0.5425 - val_accuracy: 0.7240\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7882 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7917 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4608 - accuracy: 0.7899 - val_loss: 0.5427 - val_accuracy: 0.7240\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4602 - accuracy: 0.7934 - val_loss: 0.5428 - val_accuracy: 0.7240\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4596 - accuracy: 0.7934 - val_loss: 0.5428 - val_accuracy: 0.7240\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7934 - val_loss: 0.5430 - val_accuracy: 0.7240\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7917 - val_loss: 0.5431 - val_accuracy: 0.7188\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7188\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4579 - accuracy: 0.7934 - val_loss: 0.5433 - val_accuracy: 0.7188\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4575 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7188\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4571 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7188\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7188\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4564 - accuracy: 0.7917 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7899 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7917 - val_loss: 0.5437 - val_accuracy: 0.7188\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4552 - accuracy: 0.7899 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7899 - val_loss: 0.5439 - val_accuracy: 0.7188\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4545 - accuracy: 0.7899 - val_loss: 0.5439 - val_accuracy: 0.7188\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.7934 - val_loss: 0.5439 - val_accuracy: 0.7083\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4536 - accuracy: 0.7899 - val_loss: 0.5440 - val_accuracy: 0.7083\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4534 - accuracy: 0.7899 - val_loss: 0.5440 - val_accuracy: 0.7083\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4531 - accuracy: 0.7899 - val_loss: 0.5440 - val_accuracy: 0.7083\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.7917 - val_loss: 0.5441 - val_accuracy: 0.7083\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7917 - val_loss: 0.5442 - val_accuracy: 0.7083\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7899 - val_loss: 0.5443 - val_accuracy: 0.7083\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7917 - val_loss: 0.5443 - val_accuracy: 0.7083\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7917 - val_loss: 0.5445 - val_accuracy: 0.7083\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7917 - val_loss: 0.5445 - val_accuracy: 0.7083\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7917 - val_loss: 0.5445 - val_accuracy: 0.7083\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7917 - val_loss: 0.5446 - val_accuracy: 0.7083\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7934 - val_loss: 0.5447 - val_accuracy: 0.7083\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7083\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7899 - val_loss: 0.5447 - val_accuracy: 0.7031\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7934 - val_loss: 0.5447 - val_accuracy: 0.6979\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.5447 - val_accuracy: 0.6979\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.5447 - val_accuracy: 0.6979\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7951 - val_loss: 0.5447 - val_accuracy: 0.6979\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7917 - val_loss: 0.5448 - val_accuracy: 0.6979\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7934 - val_loss: 0.5449 - val_accuracy: 0.6979\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.5449 - val_accuracy: 0.6979\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.5450 - val_accuracy: 0.6979\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7934 - val_loss: 0.5451 - val_accuracy: 0.6979\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.5451 - val_accuracy: 0.7031\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.5452 - val_accuracy: 0.6979\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7882 - val_loss: 0.5452 - val_accuracy: 0.6979\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7934 - val_loss: 0.5453 - val_accuracy: 0.6979\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5454 - val_accuracy: 0.6979\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.5455 - val_accuracy: 0.6979\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7899 - val_loss: 0.5455 - val_accuracy: 0.6979\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.5456 - val_accuracy: 0.6979\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.5457 - val_accuracy: 0.6979\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5458 - val_accuracy: 0.6979\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.5458 - val_accuracy: 0.6979\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5459 - val_accuracy: 0.6979\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5459 - val_accuracy: 0.6979\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5460 - val_accuracy: 0.6979\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7934 - val_loss: 0.5460 - val_accuracy: 0.6979\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.5461 - val_accuracy: 0.6979\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.5461 - val_accuracy: 0.6979\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.5462 - val_accuracy: 0.6979\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4430 - accuracy: 0.7951 - val_loss: 0.5462 - val_accuracy: 0.6979\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.5463 - val_accuracy: 0.6979\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5463 - val_accuracy: 0.6979\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.5464 - val_accuracy: 0.6979\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.5465 - val_accuracy: 0.6979\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.5465 - val_accuracy: 0.6979\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.5465 - val_accuracy: 0.6979\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.5466 - val_accuracy: 0.6979\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.5467 - val_accuracy: 0.6979\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7934 - val_loss: 0.5467 - val_accuracy: 0.6979\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4408 - accuracy: 0.7934 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4404 - accuracy: 0.7934 - val_loss: 0.5469 - val_accuracy: 0.6979\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4402 - accuracy: 0.7934 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4400 - accuracy: 0.7934 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5469 - val_accuracy: 0.6979\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4388 - accuracy: 0.7986 - val_loss: 0.5469 - val_accuracy: 0.6979\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4388 - accuracy: 0.7986 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4382 - accuracy: 0.7969 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4381 - accuracy: 0.7986 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.7986 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4375 - accuracy: 0.7986 - val_loss: 0.5467 - val_accuracy: 0.6979\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.7986 - val_loss: 0.5467 - val_accuracy: 0.6979\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7986 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.8003 - val_loss: 0.5467 - val_accuracy: 0.6979\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5467 - val_accuracy: 0.6979\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.5466 - val_accuracy: 0.6979\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4366 - accuracy: 0.7986 - val_loss: 0.5467 - val_accuracy: 0.6979\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5467 - val_accuracy: 0.6979\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.7986 - val_loss: 0.5467 - val_accuracy: 0.6979\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5466 - val_accuracy: 0.6979\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.5466 - val_accuracy: 0.6979\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.6927\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5465 - val_accuracy: 0.6927\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5464 - val_accuracy: 0.6927\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5464 - val_accuracy: 0.6875\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5465 - val_accuracy: 0.6875\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.6875\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4352 - accuracy: 0.8021 - val_loss: 0.5466 - val_accuracy: 0.6875\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.8021 - val_loss: 0.5466 - val_accuracy: 0.6875\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.8021 - val_loss: 0.5466 - val_accuracy: 0.6927\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4347 - accuracy: 0.8021 - val_loss: 0.5465 - val_accuracy: 0.6927\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4347 - accuracy: 0.8038 - val_loss: 0.5465 - val_accuracy: 0.6927\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4346 - accuracy: 0.8038 - val_loss: 0.5466 - val_accuracy: 0.6927\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.8038 - val_loss: 0.5466 - val_accuracy: 0.6927\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4343 - accuracy: 0.8038 - val_loss: 0.5466 - val_accuracy: 0.6927\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.8021 - val_loss: 0.5466 - val_accuracy: 0.6927\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.8038 - val_loss: 0.5465 - val_accuracy: 0.6927\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.8038 - val_loss: 0.5466 - val_accuracy: 0.6979\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.8038 - val_loss: 0.5466 - val_accuracy: 0.6979\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8038 - val_loss: 0.5465 - val_accuracy: 0.6979\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8038 - val_loss: 0.5466 - val_accuracy: 0.7031\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8038 - val_loss: 0.5466 - val_accuracy: 0.7031\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.5465 - val_accuracy: 0.7031\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8021 - val_loss: 0.5465 - val_accuracy: 0.7031\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8038 - val_loss: 0.5464 - val_accuracy: 0.7031\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8038 - val_loss: 0.5464 - val_accuracy: 0.7031\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.8021 - val_loss: 0.5464 - val_accuracy: 0.7031\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.8021 - val_loss: 0.5464 - val_accuracy: 0.7031\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8038 - val_loss: 0.5464 - val_accuracy: 0.7031\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.8038 - val_loss: 0.5463 - val_accuracy: 0.7031\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4326 - accuracy: 0.8038 - val_loss: 0.5463 - val_accuracy: 0.7031\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4324 - accuracy: 0.8038 - val_loss: 0.5462 - val_accuracy: 0.7031\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.8038 - val_loss: 0.5462 - val_accuracy: 0.7031\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.8021 - val_loss: 0.5461 - val_accuracy: 0.7031\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4320 - accuracy: 0.8021 - val_loss: 0.5461 - val_accuracy: 0.7031\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8021 - val_loss: 0.5460 - val_accuracy: 0.7083\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.8073 - val_loss: 0.5460 - val_accuracy: 0.7083\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.8038 - val_loss: 0.5461 - val_accuracy: 0.7083\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.8056 - val_loss: 0.5461 - val_accuracy: 0.7083\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.8056 - val_loss: 0.5461 - val_accuracy: 0.7083\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4314 - accuracy: 0.8056 - val_loss: 0.5460 - val_accuracy: 0.7083\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8038 - val_loss: 0.5460 - val_accuracy: 0.7083\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8038 - val_loss: 0.5460 - val_accuracy: 0.7083\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.8038 - val_loss: 0.5459 - val_accuracy: 0.7135\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8073 - val_loss: 0.5460 - val_accuracy: 0.7135\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8056 - val_loss: 0.5460 - val_accuracy: 0.7135\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4308 - accuracy: 0.8056 - val_loss: 0.5460 - val_accuracy: 0.7135\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8090 - val_loss: 0.5459 - val_accuracy: 0.7135\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.8073 - val_loss: 0.5459 - val_accuracy: 0.7135\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4306 - accuracy: 0.8056 - val_loss: 0.5458 - val_accuracy: 0.7135\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8090 - val_loss: 0.5458 - val_accuracy: 0.7135\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.8090 - val_loss: 0.5457 - val_accuracy: 0.7135\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4302 - accuracy: 0.8090 - val_loss: 0.5457 - val_accuracy: 0.7135\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.8056 - val_loss: 0.5456 - val_accuracy: 0.7135\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8073 - val_loss: 0.5456 - val_accuracy: 0.7135\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.8073 - val_loss: 0.5455 - val_accuracy: 0.7135\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.8073 - val_loss: 0.5455 - val_accuracy: 0.7135\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.8056 - val_loss: 0.5455 - val_accuracy: 0.7135\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4297 - accuracy: 0.8090 - val_loss: 0.5454 - val_accuracy: 0.7135\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.8073 - val_loss: 0.5453 - val_accuracy: 0.7135\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.8073 - val_loss: 0.5452 - val_accuracy: 0.7135\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4294 - accuracy: 0.8056 - val_loss: 0.5452 - val_accuracy: 0.7135\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.8056 - val_loss: 0.5451 - val_accuracy: 0.7135\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8073 - val_loss: 0.5451 - val_accuracy: 0.7135\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4290 - accuracy: 0.8073 - val_loss: 0.5451 - val_accuracy: 0.7135\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4290 - accuracy: 0.8073 - val_loss: 0.5450 - val_accuracy: 0.7135\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4289 - accuracy: 0.8090 - val_loss: 0.5451 - val_accuracy: 0.7135\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4289 - accuracy: 0.8073 - val_loss: 0.5451 - val_accuracy: 0.7135\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4288 - accuracy: 0.8073 - val_loss: 0.5450 - val_accuracy: 0.7135\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4286 - accuracy: 0.8073 - val_loss: 0.5450 - val_accuracy: 0.7135\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4286 - accuracy: 0.8073 - val_loss: 0.5450 - val_accuracy: 0.7135\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4285 - accuracy: 0.8073 - val_loss: 0.5451 - val_accuracy: 0.7135\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8073 - val_loss: 0.5450 - val_accuracy: 0.7135\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8073 - val_loss: 0.5448 - val_accuracy: 0.7135\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.8073 - val_loss: 0.5449 - val_accuracy: 0.7135\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4281 - accuracy: 0.8073 - val_loss: 0.5448 - val_accuracy: 0.7135\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8073 - val_loss: 0.5448 - val_accuracy: 0.7135\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8073 - val_loss: 0.5447 - val_accuracy: 0.7135\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8073 - val_loss: 0.5446 - val_accuracy: 0.7135\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8073 - val_loss: 0.5446 - val_accuracy: 0.7135\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4275 - accuracy: 0.8073 - val_loss: 0.5444 - val_accuracy: 0.7135\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8056 - val_loss: 0.5443 - val_accuracy: 0.7135\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.8073 - val_loss: 0.5442 - val_accuracy: 0.7135\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4273 - accuracy: 0.8073 - val_loss: 0.5442 - val_accuracy: 0.7135\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4272 - accuracy: 0.8073 - val_loss: 0.5441 - val_accuracy: 0.7135\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4271 - accuracy: 0.8073 - val_loss: 0.5440 - val_accuracy: 0.7135\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4269 - accuracy: 0.8073 - val_loss: 0.5440 - val_accuracy: 0.7135\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4269 - accuracy: 0.8090 - val_loss: 0.5440 - val_accuracy: 0.7135\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4268 - accuracy: 0.8073 - val_loss: 0.5438 - val_accuracy: 0.7135\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4266 - accuracy: 0.8090 - val_loss: 0.5439 - val_accuracy: 0.7135\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4266 - accuracy: 0.8056 - val_loss: 0.5437 - val_accuracy: 0.7135\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4266 - accuracy: 0.8073 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4264 - accuracy: 0.8073 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4263 - accuracy: 0.8073 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.8090 - val_loss: 0.5436 - val_accuracy: 0.7135\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4262 - accuracy: 0.8073 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4261 - accuracy: 0.8073 - val_loss: 0.5434 - val_accuracy: 0.7188\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.8073 - val_loss: 0.5433 - val_accuracy: 0.7188\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4259 - accuracy: 0.8056 - val_loss: 0.5432 - val_accuracy: 0.7188\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4257 - accuracy: 0.8073 - val_loss: 0.5432 - val_accuracy: 0.7188\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4257 - accuracy: 0.8090 - val_loss: 0.5431 - val_accuracy: 0.7188\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4257 - accuracy: 0.8056 - val_loss: 0.5429 - val_accuracy: 0.7188\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.8090 - val_loss: 0.5431 - val_accuracy: 0.7188\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8090 - val_loss: 0.5429 - val_accuracy: 0.7188\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.8073 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.8090 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.8090 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4251 - accuracy: 0.8090 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8073 - val_loss: 0.5427 - val_accuracy: 0.7188\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8090 - val_loss: 0.5426 - val_accuracy: 0.7188\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8090 - val_loss: 0.5426 - val_accuracy: 0.7188\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8090 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4247 - accuracy: 0.8090 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4246 - accuracy: 0.8108 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4246 - accuracy: 0.8073 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4244 - accuracy: 0.8108 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4245 - accuracy: 0.8108 - val_loss: 0.5423 - val_accuracy: 0.7240\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4244 - accuracy: 0.8125 - val_loss: 0.5422 - val_accuracy: 0.7240\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4242 - accuracy: 0.8108 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4241 - accuracy: 0.8125 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.8108 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4240 - accuracy: 0.8108 - val_loss: 0.5420 - val_accuracy: 0.7188\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4240 - accuracy: 0.8108 - val_loss: 0.5419 - val_accuracy: 0.7188\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4238 - accuracy: 0.8125 - val_loss: 0.5419 - val_accuracy: 0.7188\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4238 - accuracy: 0.8125 - val_loss: 0.5418 - val_accuracy: 0.7188\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4237 - accuracy: 0.8125 - val_loss: 0.5418 - val_accuracy: 0.7188\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4237 - accuracy: 0.8125 - val_loss: 0.5417 - val_accuracy: 0.7188\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.8125 - val_loss: 0.5417 - val_accuracy: 0.7188\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4235 - accuracy: 0.8108 - val_loss: 0.5416 - val_accuracy: 0.7188\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4235 - accuracy: 0.8125 - val_loss: 0.5415 - val_accuracy: 0.7188\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4233 - accuracy: 0.8125 - val_loss: 0.5416 - val_accuracy: 0.7188\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8108 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8142 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8108 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8108 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8125 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8090 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8125 - val_loss: 0.5412 - val_accuracy: 0.7240\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8108 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8108 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8108 - val_loss: 0.5411 - val_accuracy: 0.7240\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8090 - val_loss: 0.5411 - val_accuracy: 0.7240\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8108 - val_loss: 0.5410 - val_accuracy: 0.7240\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8108 - val_loss: 0.5410 - val_accuracy: 0.7240\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8108 - val_loss: 0.5409 - val_accuracy: 0.7240\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.8125 - val_loss: 0.5409 - val_accuracy: 0.7240\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7240\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7240\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7240\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8142 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7240\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7240\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7240\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4204 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7240\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4195 - accuracy: 0.8073 - val_loss: 0.5404 - val_accuracy: 0.7240\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7240\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4194 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7240\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4194 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7240\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4193 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7240\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.4193 - accuracy: 0.8073 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4192 - accuracy: 0.8073 - val_loss: 0.5404 - val_accuracy: 0.7240\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4191 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7292\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4190 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4189 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4189 - accuracy: 0.8090 - val_loss: 0.5404 - val_accuracy: 0.7292\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4186 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4188 - accuracy: 0.8073 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.8073 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4184 - accuracy: 0.8073 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.8038 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.8056 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4182 - accuracy: 0.8073 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4181 - accuracy: 0.8073 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4180 - accuracy: 0.8073 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4180 - accuracy: 0.8056 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4180 - accuracy: 0.8073 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4178 - accuracy: 0.8073 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8056 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8056 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8073 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8073 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8073 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8073 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8056 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8090 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8056 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8056 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8073 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8056 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8073 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8073 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8090 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8073 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8056 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8073 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8056 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8073 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8056 - val_loss: 0.5392 - val_accuracy: 0.7448\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8038 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8038 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8038 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8038 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8038 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8038 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8038 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8056 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8038 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8021 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5382 - val_accuracy: 0.7552\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8056 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8003 - val_loss: 0.5378 - val_accuracy: 0.7552\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8038 - val_loss: 0.5377 - val_accuracy: 0.7552\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5373 - val_accuracy: 0.7552\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.5373 - val_accuracy: 0.7552\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.8038 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5373 - val_accuracy: 0.7552\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4137 - accuracy: 0.8038 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4136 - accuracy: 0.8038 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4133 - accuracy: 0.8038 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4133 - accuracy: 0.8038 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.8038 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4130 - accuracy: 0.8038 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4127 - accuracy: 0.8056 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8056 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8038 - val_loss: 0.5363 - val_accuracy: 0.7500\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.8038 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8056 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4122 - accuracy: 0.8038 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8038 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8056 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8056 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4114 - accuracy: 0.8038 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8021 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4111 - accuracy: 0.8021 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4111 - accuracy: 0.8021 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4109 - accuracy: 0.8056 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8038 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8056 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.8056 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4105 - accuracy: 0.8038 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4104 - accuracy: 0.8038 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4104 - accuracy: 0.8038 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4104 - accuracy: 0.8038 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8090 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8090 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4099 - accuracy: 0.8056 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8073 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8073 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4095 - accuracy: 0.8073 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8073 - val_loss: 0.5337 - val_accuracy: 0.7500\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5337 - val_accuracy: 0.7500\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8073 - val_loss: 0.5337 - val_accuracy: 0.7500\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4091 - accuracy: 0.8073 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.8073 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8073 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4088 - accuracy: 0.8090 - val_loss: 0.5337 - val_accuracy: 0.7500\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.5337 - val_accuracy: 0.7500\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.8073 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8108 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4082 - accuracy: 0.8108 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4081 - accuracy: 0.8090 - val_loss: 0.5333 - val_accuracy: 0.7500\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.5333 - val_accuracy: 0.7500\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8090 - val_loss: 0.5333 - val_accuracy: 0.7500\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4079 - accuracy: 0.8073 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8090 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8108 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8073 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.8090 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.8125 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8056 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8125 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8125 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8125 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8125 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8090 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8073 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8090 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8108 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8142 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8056 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8073 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8108 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8160 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.5344 - val_accuracy: 0.7448\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.5346 - val_accuracy: 0.7448\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5344 - val_accuracy: 0.7448\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8142 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8142 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4045 - accuracy: 0.8125 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4044 - accuracy: 0.8142 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4042 - accuracy: 0.8142 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4040 - accuracy: 0.8073 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4038 - accuracy: 0.8125 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8073 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8073 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8073 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8073 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8108 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.8108 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8125 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8073 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8073 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8073 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8108 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8108 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8073 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8108 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5372 - val_accuracy: 0.7500\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.5373 - val_accuracy: 0.7500\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8108 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8108 - val_loss: 0.5376 - val_accuracy: 0.7500\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5375 - val_accuracy: 0.7500\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8108 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8108 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8125 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8108 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8090 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8108 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8108 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8090 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8090 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8108 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8090 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4019 - accuracy: 0.8108 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4019 - accuracy: 0.8108 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4017 - accuracy: 0.8125 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.8108 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4017 - accuracy: 0.8125 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.8090 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.8108 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.8108 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4016 - accuracy: 0.8108 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4014 - accuracy: 0.8125 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4014 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4012 - accuracy: 0.8125 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8090 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8090 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8090 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7552\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8142 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7552\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8090 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8090 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8090 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7552\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8108 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8108 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8073 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8108 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8108 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8108 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3999 - accuracy: 0.8090 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8108 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3997 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3998 - accuracy: 0.8090 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3997 - accuracy: 0.8090 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3997 - accuracy: 0.8142 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3996 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8073 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3994 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8108 - val_loss: 0.5400 - val_accuracy: 0.7604\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8090 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8090 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8073 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8090 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8090 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7656\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3991 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.3989 - accuracy: 0.8090 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3991 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7656\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8090 - val_loss: 0.5409 - val_accuracy: 0.7604\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7604\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7604\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7656\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7656\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8090 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8090 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3989 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3986 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3988 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3985 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8108 - val_loss: 0.5410 - val_accuracy: 0.7552\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3985 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8108 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3985 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3984 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3984 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3983 - accuracy: 0.8142 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3984 - accuracy: 0.8160 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3984 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7604\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8142 - val_loss: 0.5407 - val_accuracy: 0.7604\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7604\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7604\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8142 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8125 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5411 - val_accuracy: 0.7552\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8142 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8090 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8108 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3976 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8090 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8090 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3976 - accuracy: 0.8090 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3977 - accuracy: 0.8125 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3974 - accuracy: 0.8125 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3975 - accuracy: 0.8125 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3975 - accuracy: 0.8073 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3973 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3975 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3972 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3972 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3974 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3973 - accuracy: 0.8108 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3973 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3972 - accuracy: 0.8073 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3972 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3973 - accuracy: 0.8090 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3973 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3973 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8108 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8125 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8108 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8142 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8073 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8142 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8073 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8142 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8090 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8142 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8090 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8108 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8108 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8090 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8090 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8090 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3970 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8142 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8142 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3969 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8142 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8160 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8090 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3969 - accuracy: 0.8142 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3967 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8142 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8142 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8142 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3966 - accuracy: 0.8073 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8142 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8142 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8160 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8142 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3966 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3965 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3965 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3964 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3965 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3965 - accuracy: 0.8073 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3964 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3966 - accuracy: 0.8073 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3965 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3965 - accuracy: 0.8108 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3965 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3963 - accuracy: 0.8160 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3963 - accuracy: 0.8108 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3964 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3964 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3966 - accuracy: 0.8073 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3965 - accuracy: 0.8073 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3965 - accuracy: 0.8142 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3962 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3962 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3965 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3964 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8090 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8073 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8073 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8108 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3963 - accuracy: 0.8090 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3965 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8090 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8142 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8142 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8125 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8090 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8073 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8038 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8108 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8108 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8108 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8090 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8090 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8142 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8125 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8125 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3960 - accuracy: 0.8108 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8108 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8108 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8125 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8108 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8142 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8125 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8125 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8108 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8090 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8142 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8108 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8125 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8090 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8125 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8125 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8108 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8142 - val_loss: 0.5414 - val_accuracy: 0.7552\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8125 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3957 - accuracy: 0.8125 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8125 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3954 - accuracy: 0.8108 - val_loss: 0.5423 - val_accuracy: 0.7448\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8142 - val_loss: 0.5423 - val_accuracy: 0.7448\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8125 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8125 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8125 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8108 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8142 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3952 - accuracy: 0.8125 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8142 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3953 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3953 - accuracy: 0.8142 - val_loss: 0.5426 - val_accuracy: 0.7448\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3954 - accuracy: 0.8125 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3953 - accuracy: 0.8142 - val_loss: 0.5426 - val_accuracy: 0.7448\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8125 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8142 - val_loss: 0.5426 - val_accuracy: 0.7448\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8142 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8160 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3951 - accuracy: 0.8160 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3949 - accuracy: 0.8125 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3953 - accuracy: 0.8125 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3951 - accuracy: 0.8160 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3951 - accuracy: 0.8125 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3948 - accuracy: 0.8142 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3948 - accuracy: 0.8125 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3951 - accuracy: 0.8160 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3948 - accuracy: 0.8160 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8160 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8142 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8160 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8142 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3947 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8177 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8142 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8160 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8108 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3947 - accuracy: 0.8160 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8177 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8160 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8142 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8160 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8142 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3945 - accuracy: 0.8160 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8142 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3944 - accuracy: 0.8160 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8160 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8177 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8142 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8160 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8160 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8142 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8160 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8177 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3942 - accuracy: 0.8177 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3942 - accuracy: 0.8160 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8125 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8177 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8177 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8177 - val_loss: 0.5424 - val_accuracy: 0.7604\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8160 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8160 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8177 - val_loss: 0.5427 - val_accuracy: 0.7604\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8142 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.5428 - val_accuracy: 0.7604\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8177 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8142 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3940 - accuracy: 0.8160 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8177 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3940 - accuracy: 0.8177 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3940 - accuracy: 0.8160 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3938 - accuracy: 0.8160 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8160 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8177 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8177 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3938 - accuracy: 0.8160 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8108 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8160 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8142 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3939 - accuracy: 0.8177 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3937 - accuracy: 0.8177 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8142 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8142 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8177 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8177 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3937 - accuracy: 0.8160 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8142 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8160 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3935 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3936 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3936 - accuracy: 0.8160 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3934 - accuracy: 0.8160 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3936 - accuracy: 0.8177 - val_loss: 0.5436 - val_accuracy: 0.7552\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3936 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7604\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3936 - accuracy: 0.8160 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3932 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8160 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3932 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3930 - accuracy: 0.8177 - val_loss: 0.5436 - val_accuracy: 0.7552\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3933 - accuracy: 0.8212 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8177 - val_loss: 0.5437 - val_accuracy: 0.7552\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5436 - val_accuracy: 0.7552\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8194 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3932 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8194 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8160 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3930 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8212 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3929 - accuracy: 0.8194 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8212 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8194 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8194 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8194 - val_loss: 0.5436 - val_accuracy: 0.7552\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8194 - val_loss: 0.5437 - val_accuracy: 0.7552\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8194 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3927 - accuracy: 0.8247 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8212 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8194 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3928 - accuracy: 0.8194 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8177 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8229 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8194 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8229 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8247 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3925 - accuracy: 0.8212 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8177 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8194 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8212 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3923 - accuracy: 0.8229 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3923 - accuracy: 0.8212 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8212 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3922 - accuracy: 0.8212 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8212 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8229 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8212 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3920 - accuracy: 0.8212 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8229 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3920 - accuracy: 0.8229 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8212 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3919 - accuracy: 0.8247 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3921 - accuracy: 0.8160 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.8229 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3918 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.8229 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8247 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.8229 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.8229 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8194 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8212 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8212 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3916 - accuracy: 0.8212 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8247 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8212 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3915 - accuracy: 0.8212 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8229 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8212 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3917 - accuracy: 0.8212 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8212 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8229 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8247 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3915 - accuracy: 0.8212 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3916 - accuracy: 0.8194 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3912 - accuracy: 0.8229 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3916 - accuracy: 0.8160 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3915 - accuracy: 0.8194 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8194 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3912 - accuracy: 0.8229 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3913 - accuracy: 0.8177 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3913 - accuracy: 0.8229 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3915 - accuracy: 0.8194 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3912 - accuracy: 0.8229 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3913 - accuracy: 0.8229 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.8177 - val_loss: 0.5440 - val_accuracy: 0.7500\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3912 - accuracy: 0.8212 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3911 - accuracy: 0.8212 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3911 - accuracy: 0.8194 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3912 - accuracy: 0.8247 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3912 - accuracy: 0.8177 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3911 - accuracy: 0.8229 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3911 - accuracy: 0.8194 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3912 - accuracy: 0.8194 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8194 - val_loss: 0.5440 - val_accuracy: 0.7500\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3912 - accuracy: 0.8229 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3912 - accuracy: 0.8229 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3909 - accuracy: 0.8212 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3909 - accuracy: 0.8177 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3913 - accuracy: 0.8194 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8212 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3912 - accuracy: 0.8194 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8229 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8229 - val_loss: 0.5441 - val_accuracy: 0.7500\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.8212 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3910 - accuracy: 0.8212 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8194 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8247 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.8212 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8194 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.8212 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.8177 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3908 - accuracy: 0.8177 - val_loss: 0.5441 - val_accuracy: 0.7500\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.8160 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8177 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3908 - accuracy: 0.8212 - val_loss: 0.5441 - val_accuracy: 0.7500\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3910 - accuracy: 0.8229 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8177 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3907 - accuracy: 0.8247 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3907 - accuracy: 0.8194 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3907 - accuracy: 0.8194 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8194 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.8247 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8212 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8177 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3907 - accuracy: 0.8212 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3907 - accuracy: 0.8212 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3905 - accuracy: 0.8194 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3908 - accuracy: 0.8160 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8229 - val_loss: 0.5438 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "\n",
        "run_hist_1.history.keys()\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "ijzBIHaynWpW",
        "outputId": "90ec641b-bc12-42a7-8f11-b6ea35254d92"
      },
      "id": "ijzBIHaynWpW",
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cc9a20d30a0>"
            ]
          },
          "metadata": {},
          "execution_count": 156
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_1.history.keys()\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"accuracy\"],'r', marker='.', label=\"Train Accuracy\")\n",
        "ax.plot(run_hist_1.history[\"val_accuracy\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "cqSRHSOKo5ti",
        "outputId": "8cb40221-bf6f-4c57-cbe2-8286354924de"
      },
      "id": "cqSRHSOKo5ti",
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cc99010c9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 157
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the roc curve for the predictions\n",
        "\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)\n",
        "y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(int)\n",
        "\n",
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "qkHf3fJonY5e",
        "outputId": "cc32b27a-ac2f-47b2-e8bf-c3f1015a758a"
      },
      "id": "qkHf3fJonY5e",
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "accuracy is 0.750\n",
            "roc-auc is 0.800\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use different learning rates, numbers of epochs, and network structures.\n",
        "model.compile(SGD(lr = .05), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UBIMTMRTpqZO",
        "outputId": "014b8a6b-a276-4774-efce-d11197c6087f"
      },
      "id": "UBIMTMRTpqZO",
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "18/18 [==============================] - 1s 15ms/step - loss: 0.6662 - accuracy: 0.6667 - val_loss: 0.6817 - val_accuracy: 0.6458\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6425 - accuracy: 0.6632 - val_loss: 0.6604 - val_accuracy: 0.6458\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6240 - accuracy: 0.6684 - val_loss: 0.6437 - val_accuracy: 0.6510\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.6719 - val_loss: 0.6303 - val_accuracy: 0.6615\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.6788 - val_loss: 0.6193 - val_accuracy: 0.6667\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.6858 - val_loss: 0.6103 - val_accuracy: 0.6667\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.6927 - val_loss: 0.6025 - val_accuracy: 0.6719\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.6962 - val_loss: 0.5958 - val_accuracy: 0.6875\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5618 - accuracy: 0.6944 - val_loss: 0.5900 - val_accuracy: 0.6875\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.6979 - val_loss: 0.5848 - val_accuracy: 0.6979\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7049 - val_loss: 0.5803 - val_accuracy: 0.6927\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7083 - val_loss: 0.5762 - val_accuracy: 0.7083\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5394 - accuracy: 0.7101 - val_loss: 0.5726 - val_accuracy: 0.7083\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7118 - val_loss: 0.5693 - val_accuracy: 0.7083\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7240 - val_loss: 0.5663 - val_accuracy: 0.7188\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7274 - val_loss: 0.5636 - val_accuracy: 0.7188\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7326 - val_loss: 0.5611 - val_accuracy: 0.7292\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7500 - val_loss: 0.5589 - val_accuracy: 0.7344\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7552 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.7622 - val_loss: 0.5551 - val_accuracy: 0.7292\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7691 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7674 - val_loss: 0.5521 - val_accuracy: 0.7448\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7639 - val_loss: 0.5508 - val_accuracy: 0.7448\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7639 - val_loss: 0.5497 - val_accuracy: 0.7448\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.7622 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
            "Epoch 26/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7622 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
            "Epoch 27/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7622 - val_loss: 0.5467 - val_accuracy: 0.7448\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.7622 - val_loss: 0.5459 - val_accuracy: 0.7448\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.7656 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7622 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7604 - val_loss: 0.5441 - val_accuracy: 0.7448\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7604 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7604 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.7622 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7639 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7656 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7639 - val_loss: 0.5420 - val_accuracy: 0.7500\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7691 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7656 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7674 - val_loss: 0.5413 - val_accuracy: 0.7604\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7674 - val_loss: 0.5412 - val_accuracy: 0.7604\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.5410 - val_accuracy: 0.7552\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7674 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7691 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7708 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 51/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7708 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 52/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7674 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7708 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7674 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7656 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5407 - val_accuracy: 0.7448\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7656 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7639 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7708 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7656 - val_loss: 0.5409 - val_accuracy: 0.7396\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7656 - val_loss: 0.5410 - val_accuracy: 0.7396\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7639 - val_loss: 0.5411 - val_accuracy: 0.7448\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7656 - val_loss: 0.5412 - val_accuracy: 0.7448\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7622 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7622 - val_loss: 0.5414 - val_accuracy: 0.7396\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7639 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7622 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7622 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7639 - val_loss: 0.5418 - val_accuracy: 0.7396\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7639 - val_loss: 0.5418 - val_accuracy: 0.7396\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7622 - val_loss: 0.5419 - val_accuracy: 0.7396\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7656 - val_loss: 0.5420 - val_accuracy: 0.7396\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7622 - val_loss: 0.5420 - val_accuracy: 0.7396\n",
            "Epoch 76/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7639 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
            "Epoch 77/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.5422 - val_accuracy: 0.7396\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7639 - val_loss: 0.5423 - val_accuracy: 0.7396\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7622 - val_loss: 0.5423 - val_accuracy: 0.7396\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4704 - accuracy: 0.7639 - val_loss: 0.5424 - val_accuracy: 0.7396\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7639 - val_loss: 0.5424 - val_accuracy: 0.7396\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7639 - val_loss: 0.5425 - val_accuracy: 0.7396\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7656 - val_loss: 0.5425 - val_accuracy: 0.7396\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7622 - val_loss: 0.5426 - val_accuracy: 0.7396\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7622 - val_loss: 0.5426 - val_accuracy: 0.7396\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.7656 - val_loss: 0.5427 - val_accuracy: 0.7396\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4691 - accuracy: 0.7639 - val_loss: 0.5428 - val_accuracy: 0.7344\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4689 - accuracy: 0.7656 - val_loss: 0.5428 - val_accuracy: 0.7344\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.7656 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7674 - val_loss: 0.5430 - val_accuracy: 0.7344\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4684 - accuracy: 0.7691 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7656 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4676 - accuracy: 0.7674 - val_loss: 0.5435 - val_accuracy: 0.7292\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4676 - accuracy: 0.7656 - val_loss: 0.5435 - val_accuracy: 0.7292\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4674 - accuracy: 0.7656 - val_loss: 0.5436 - val_accuracy: 0.7292\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4672 - accuracy: 0.7674 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.7674 - val_loss: 0.5439 - val_accuracy: 0.7292\n",
            "Epoch 101/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7674 - val_loss: 0.5440 - val_accuracy: 0.7292\n",
            "Epoch 102/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7674 - val_loss: 0.5441 - val_accuracy: 0.7292\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7674 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7674 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7674 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7674 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7656 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7639 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7656 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7622 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7656 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7639 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7674 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7656 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7656 - val_loss: 0.5450 - val_accuracy: 0.7240\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7656 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7656 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7656 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7639 - val_loss: 0.5452 - val_accuracy: 0.7240\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7240\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7639 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7622 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.7622 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7622 - val_loss: 0.5455 - val_accuracy: 0.7240\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7622 - val_loss: 0.5455 - val_accuracy: 0.7240\n",
            "Epoch 126/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7604 - val_loss: 0.5455 - val_accuracy: 0.7240\n",
            "Epoch 127/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7622 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7622 - val_loss: 0.5455 - val_accuracy: 0.7240\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7604 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7622 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7622 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7622 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7622 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7656 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7639 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7639 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.7639 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7639 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7622 - val_loss: 0.5450 - val_accuracy: 0.7344\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7622 - val_loss: 0.5449 - val_accuracy: 0.7292\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7639 - val_loss: 0.5449 - val_accuracy: 0.7292\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7604 - val_loss: 0.5449 - val_accuracy: 0.7292\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4620 - accuracy: 0.7622 - val_loss: 0.5448 - val_accuracy: 0.7292\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7622 - val_loss: 0.5447 - val_accuracy: 0.7292\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7639 - val_loss: 0.5447 - val_accuracy: 0.7292\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7622 - val_loss: 0.5446 - val_accuracy: 0.7292\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7622 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7587 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7639 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 151/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7622 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
            "Epoch 152/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7587 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7604 - val_loss: 0.5443 - val_accuracy: 0.7344\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7604 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4609 - accuracy: 0.7622 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7604 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7604 - val_loss: 0.5441 - val_accuracy: 0.7396\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7604 - val_loss: 0.5441 - val_accuracy: 0.7396\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7622 - val_loss: 0.5441 - val_accuracy: 0.7396\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7604 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7604 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7639 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7587 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7622 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7622 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7639 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7587 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7569 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7639 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7587 - val_loss: 0.5433 - val_accuracy: 0.7396\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7587 - val_loss: 0.5433 - val_accuracy: 0.7396\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7622 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7587 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7569 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7569 - val_loss: 0.5430 - val_accuracy: 0.7396\n",
            "Epoch 176/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4587 - accuracy: 0.7569 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
            "Epoch 177/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7569 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7552 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7552 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7587 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7552 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7587 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7604 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7604 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7587 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7587 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7604 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7569 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7569 - val_loss: 0.5425 - val_accuracy: 0.7240\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7552 - val_loss: 0.5426 - val_accuracy: 0.7240\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7569 - val_loss: 0.5425 - val_accuracy: 0.7240\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7587 - val_loss: 0.5425 - val_accuracy: 0.7240\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7569 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7587 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7569 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7587 - val_loss: 0.5424 - val_accuracy: 0.7292\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4561 - accuracy: 0.7587 - val_loss: 0.5424 - val_accuracy: 0.7292\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7587 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7587 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7587 - val_loss: 0.5423 - val_accuracy: 0.7292\n",
            "Epoch 201/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7569 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
            "Epoch 202/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.7587 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4554 - accuracy: 0.7569 - val_loss: 0.5421 - val_accuracy: 0.7292\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4554 - accuracy: 0.7604 - val_loss: 0.5420 - val_accuracy: 0.7292\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4551 - accuracy: 0.7604 - val_loss: 0.5418 - val_accuracy: 0.7292\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4550 - accuracy: 0.7569 - val_loss: 0.5417 - val_accuracy: 0.7344\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4549 - accuracy: 0.7569 - val_loss: 0.5416 - val_accuracy: 0.7344\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7587 - val_loss: 0.5416 - val_accuracy: 0.7344\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7569 - val_loss: 0.5416 - val_accuracy: 0.7344\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4545 - accuracy: 0.7569 - val_loss: 0.5414 - val_accuracy: 0.7344\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4545 - accuracy: 0.7587 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.7587 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4542 - accuracy: 0.7569 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4542 - accuracy: 0.7552 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4541 - accuracy: 0.7569 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7587 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4536 - accuracy: 0.7587 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4536 - accuracy: 0.7569 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4533 - accuracy: 0.7587 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.7587 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4532 - accuracy: 0.7587 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7587 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7569 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7587 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7552 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 226/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7552 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 227/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7552 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7552 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7552 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7569 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7552 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7552 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7535 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7535 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7552 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7535 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7552 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7552 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7587 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7552 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7604 - val_loss: 0.5396 - val_accuracy: 0.7292\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7622 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7569 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7622 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7587 - val_loss: 0.5396 - val_accuracy: 0.7240\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7656 - val_loss: 0.5395 - val_accuracy: 0.7240\n",
            "Epoch 247/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7622 - val_loss: 0.5394 - val_accuracy: 0.7240\n",
            "Epoch 248/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7639 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
            "Epoch 249/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7639 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
            "Epoch 250/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.7656 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 251/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7604 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
            "Epoch 252/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7622 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
            "Epoch 253/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7639 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
            "Epoch 254/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7639 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 255/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7656 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 256/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7622 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 257/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7639 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
            "Epoch 258/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7587 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 259/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7604 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 260/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7656 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
            "Epoch 261/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7622 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 262/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7622 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 263/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7622 - val_loss: 0.5394 - val_accuracy: 0.7240\n",
            "Epoch 264/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7587 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 265/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7604 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 266/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7587 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 267/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7604 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
            "Epoch 268/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7604 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
            "Epoch 269/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7604 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
            "Epoch 270/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7604 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
            "Epoch 271/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7604 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
            "Epoch 272/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7639 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
            "Epoch 273/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7604 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
            "Epoch 274/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7639 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
            "Epoch 275/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7587 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
            "Epoch 276/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7604 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
            "Epoch 277/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7569 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
            "Epoch 278/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7604 - val_loss: 0.5396 - val_accuracy: 0.7292\n",
            "Epoch 279/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7604 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 280/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7622 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 281/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7604 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 282/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7622 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 283/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7604 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 284/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7604 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 285/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7604 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 286/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7622 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 287/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7639 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
            "Epoch 288/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7604 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 289/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7604 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 290/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7604 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
            "Epoch 291/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7656 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 292/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4453 - accuracy: 0.7604 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 293/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7622 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 294/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7639 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 295/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7622 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 296/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7656 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 297/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7604 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 298/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7639 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 299/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7622 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 300/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7587 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 301/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7587 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 302/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7604 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 303/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7622 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 304/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7604 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 305/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.7622 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 306/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7622 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 307/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7604 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 308/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7622 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 309/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7604 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
            "Epoch 310/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7604 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 311/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7587 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 312/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7604 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 313/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7622 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 314/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7639 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 315/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7622 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
            "Epoch 316/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7604 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
            "Epoch 317/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7622 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 318/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7622 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 319/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7604 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 320/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7622 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 321/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7587 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 322/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4428 - accuracy: 0.7604 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 323/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4426 - accuracy: 0.7604 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 324/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.7622 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 325/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4423 - accuracy: 0.7656 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 326/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4423 - accuracy: 0.7622 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 327/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.7604 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 328/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7639 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
            "Epoch 329/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4420 - accuracy: 0.7604 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 330/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7622 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 331/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7656 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 332/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4420 - accuracy: 0.7656 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 333/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4418 - accuracy: 0.7639 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
            "Epoch 334/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4419 - accuracy: 0.7622 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
            "Epoch 335/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4417 - accuracy: 0.7639 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 336/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4415 - accuracy: 0.7656 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
            "Epoch 337/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4413 - accuracy: 0.7656 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 338/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4413 - accuracy: 0.7639 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
            "Epoch 339/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.7656 - val_loss: 0.5396 - val_accuracy: 0.7292\n",
            "Epoch 340/500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4410 - accuracy: 0.7622 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
            "Epoch 341/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4410 - accuracy: 0.7639 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 342/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7639 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 343/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7639 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 344/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7656 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 345/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7691 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 346/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7674 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 347/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.7691 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
            "Epoch 348/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7639 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
            "Epoch 349/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7691 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
            "Epoch 350/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7674 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
            "Epoch 351/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7656 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
            "Epoch 352/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7674 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
            "Epoch 353/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7674 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
            "Epoch 354/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.7674 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
            "Epoch 355/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7674 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
            "Epoch 356/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7691 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
            "Epoch 357/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7708 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
            "Epoch 358/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7674 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
            "Epoch 359/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7691 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
            "Epoch 360/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7691 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
            "Epoch 361/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.7691 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
            "Epoch 362/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7691 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
            "Epoch 363/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7691 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
            "Epoch 364/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7708 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
            "Epoch 365/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7691 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
            "Epoch 366/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7691 - val_loss: 0.5389 - val_accuracy: 0.7344\n",
            "Epoch 367/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.7708 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
            "Epoch 368/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.7674 - val_loss: 0.5386 - val_accuracy: 0.7344\n",
            "Epoch 369/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7674 - val_loss: 0.5386 - val_accuracy: 0.7344\n",
            "Epoch 370/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7691 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 371/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7691 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 372/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7708 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 373/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7691 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
            "Epoch 374/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7691 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
            "Epoch 375/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7691 - val_loss: 0.5385 - val_accuracy: 0.7292\n",
            "Epoch 376/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7674 - val_loss: 0.5385 - val_accuracy: 0.7344\n",
            "Epoch 377/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7691 - val_loss: 0.5385 - val_accuracy: 0.7344\n",
            "Epoch 378/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7674 - val_loss: 0.5385 - val_accuracy: 0.7344\n",
            "Epoch 379/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7674 - val_loss: 0.5386 - val_accuracy: 0.7344\n",
            "Epoch 380/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7691 - val_loss: 0.5385 - val_accuracy: 0.7344\n",
            "Epoch 381/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7708 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 382/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4376 - accuracy: 0.7691 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 383/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7708 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
            "Epoch 384/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7674 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
            "Epoch 385/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7708 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 386/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7708 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 387/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7691 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
            "Epoch 388/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7691 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 389/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7708 - val_loss: 0.5384 - val_accuracy: 0.7292\n",
            "Epoch 390/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7743 - val_loss: 0.5383 - val_accuracy: 0.7292\n",
            "Epoch 391/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7691 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
            "Epoch 392/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7708 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
            "Epoch 393/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7743 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
            "Epoch 394/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7691 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 395/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.7743 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 396/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7708 - val_loss: 0.5385 - val_accuracy: 0.7292\n",
            "Epoch 397/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7708 - val_loss: 0.5383 - val_accuracy: 0.7292\n",
            "Epoch 398/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7726 - val_loss: 0.5383 - val_accuracy: 0.7292\n",
            "Epoch 399/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.7743 - val_loss: 0.5383 - val_accuracy: 0.7292\n",
            "Epoch 400/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7726 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 401/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7726 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
            "Epoch 402/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7726 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
            "Epoch 403/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7726 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
            "Epoch 404/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.7743 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 405/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7726 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
            "Epoch 406/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7760 - val_loss: 0.5383 - val_accuracy: 0.7292\n",
            "Epoch 407/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7708 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
            "Epoch 408/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7726 - val_loss: 0.5384 - val_accuracy: 0.7292\n",
            "Epoch 409/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7743 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 410/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7726 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
            "Epoch 411/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7743 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
            "Epoch 412/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7708 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
            "Epoch 413/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
            "Epoch 414/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7743 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
            "Epoch 415/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7743 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
            "Epoch 416/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7726 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
            "Epoch 417/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7778 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
            "Epoch 418/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7778 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
            "Epoch 419/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7760 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
            "Epoch 420/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7760 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
            "Epoch 421/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.7778 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
            "Epoch 422/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.7760 - val_loss: 0.5376 - val_accuracy: 0.7344\n",
            "Epoch 423/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5375 - val_accuracy: 0.7344\n",
            "Epoch 424/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.5375 - val_accuracy: 0.7344\n",
            "Epoch 425/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.7778 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
            "Epoch 426/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7743 - val_loss: 0.5373 - val_accuracy: 0.7344\n",
            "Epoch 427/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
            "Epoch 428/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7760 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
            "Epoch 429/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
            "Epoch 430/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.7726 - val_loss: 0.5371 - val_accuracy: 0.7344\n",
            "Epoch 431/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
            "Epoch 432/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7778 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
            "Epoch 433/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.7760 - val_loss: 0.5368 - val_accuracy: 0.7344\n",
            "Epoch 434/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7778 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
            "Epoch 435/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
            "Epoch 436/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
            "Epoch 437/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4330 - accuracy: 0.7778 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
            "Epoch 438/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
            "Epoch 439/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4330 - accuracy: 0.7778 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
            "Epoch 440/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
            "Epoch 441/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.7778 - val_loss: 0.5373 - val_accuracy: 0.7396\n",
            "Epoch 442/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
            "Epoch 443/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4328 - accuracy: 0.7778 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
            "Epoch 444/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.7795 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
            "Epoch 445/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
            "Epoch 446/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4325 - accuracy: 0.7778 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
            "Epoch 447/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.7812 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
            "Epoch 448/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
            "Epoch 449/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.7812 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
            "Epoch 450/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
            "Epoch 451/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4323 - accuracy: 0.7778 - val_loss: 0.5373 - val_accuracy: 0.7448\n",
            "Epoch 452/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7812 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
            "Epoch 453/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7778 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
            "Epoch 454/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
            "Epoch 455/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4320 - accuracy: 0.7778 - val_loss: 0.5372 - val_accuracy: 0.7448\n",
            "Epoch 456/500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4318 - accuracy: 0.7778 - val_loss: 0.5369 - val_accuracy: 0.7448\n",
            "Epoch 457/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.7778 - val_loss: 0.5369 - val_accuracy: 0.7448\n",
            "Epoch 458/500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 459/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4316 - accuracy: 0.7778 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
            "Epoch 460/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.7830 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 461/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7830 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 462/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 463/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 464/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7830 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
            "Epoch 465/500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
            "Epoch 466/500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 467/500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 468/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7778 - val_loss: 0.5363 - val_accuracy: 0.7500\n",
            "Epoch 469/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5363 - val_accuracy: 0.7500\n",
            "Epoch 470/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 471/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 472/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7830 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 473/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 474/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7812 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 475/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 476/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7812 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 477/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 478/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 479/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 480/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
            "Epoch 481/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7552\n",
            "Epoch 482/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 483/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7830 - val_loss: 0.5355 - val_accuracy: 0.7552\n",
            "Epoch 484/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.5355 - val_accuracy: 0.7552\n",
            "Epoch 485/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 486/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7830 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 487/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 488/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.7830 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 489/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 490/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5351 - val_accuracy: 0.7552\n",
            "Epoch 491/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.7830 - val_loss: 0.5348 - val_accuracy: 0.7552\n",
            "Epoch 492/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
            "Epoch 493/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
            "Epoch 494/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
            "Epoch 495/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5347 - val_accuracy: 0.7604\n",
            "Epoch 496/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
            "Epoch 497/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
            "Epoch 498/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
            "Epoch 499/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7656\n",
            "Epoch 500/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5346 - val_accuracy: 0.7656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "run_hist_1.history.keys()\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "i4wDRBmQKerK",
        "outputId": "edba92fc-1960-4787-f6ae-9987ab2a93eb"
      },
      "id": "i4wDRBmQKerK",
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cc999125780>"
            ]
          },
          "metadata": {},
          "execution_count": 165
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use different learning rates, numbers of epochs, and network structures.\n",
        "model.compile(SGD(lr = .01), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "G_d-NcEDp_9Z",
        "outputId": "38c35fb8-7a3a-4430-94c2-8d5b93f982d3"
      },
      "id": "G_d-NcEDp_9Z",
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 1s 16ms/step - loss: 0.7371 - accuracy: 0.3750 - val_loss: 0.7277 - val_accuracy: 0.3854\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7183 - accuracy: 0.4010 - val_loss: 0.7135 - val_accuracy: 0.4635\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7035 - accuracy: 0.4878 - val_loss: 0.7014 - val_accuracy: 0.5312\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6910 - accuracy: 0.5382 - val_loss: 0.6906 - val_accuracy: 0.5677\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6803 - accuracy: 0.6094 - val_loss: 0.6812 - val_accuracy: 0.6406\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6712 - accuracy: 0.6597 - val_loss: 0.6731 - val_accuracy: 0.6458\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6633 - accuracy: 0.6823 - val_loss: 0.6660 - val_accuracy: 0.6771\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.6806 - val_loss: 0.6594 - val_accuracy: 0.6823\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.6875 - val_loss: 0.6531 - val_accuracy: 0.6875\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6442 - accuracy: 0.6858 - val_loss: 0.6476 - val_accuracy: 0.6927\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6840 - val_loss: 0.6423 - val_accuracy: 0.6927\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.6875 - val_loss: 0.6374 - val_accuracy: 0.6979\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6875 - val_loss: 0.6329 - val_accuracy: 0.6979\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.6875 - val_loss: 0.6287 - val_accuracy: 0.6927\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.6910 - val_loss: 0.6247 - val_accuracy: 0.6927\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6927 - val_loss: 0.6209 - val_accuracy: 0.7083\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.6979 - val_loss: 0.6170 - val_accuracy: 0.7083\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6072 - accuracy: 0.7014 - val_loss: 0.6134 - val_accuracy: 0.7135\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6032 - accuracy: 0.7014 - val_loss: 0.6098 - val_accuracy: 0.7188\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5992 - accuracy: 0.7066 - val_loss: 0.6063 - val_accuracy: 0.7188\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.7083 - val_loss: 0.6028 - val_accuracy: 0.7188\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5913 - accuracy: 0.7135 - val_loss: 0.5995 - val_accuracy: 0.7240\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.7205 - val_loss: 0.5961 - val_accuracy: 0.7292\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7205 - val_loss: 0.5928 - val_accuracy: 0.7240\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5794 - accuracy: 0.7222 - val_loss: 0.5897 - val_accuracy: 0.7240\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.7205 - val_loss: 0.5869 - val_accuracy: 0.7240\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5719 - accuracy: 0.7240 - val_loss: 0.5841 - val_accuracy: 0.7240\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5683 - accuracy: 0.7274 - val_loss: 0.5814 - val_accuracy: 0.7188\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5647 - accuracy: 0.7292 - val_loss: 0.5789 - val_accuracy: 0.7188\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5612 - accuracy: 0.7326 - val_loss: 0.5766 - val_accuracy: 0.7188\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7361 - val_loss: 0.5743 - val_accuracy: 0.7083\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7378 - val_loss: 0.5720 - val_accuracy: 0.7135\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.7413 - val_loss: 0.5696 - val_accuracy: 0.7135\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5490 - accuracy: 0.7413 - val_loss: 0.5673 - val_accuracy: 0.7083\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7448 - val_loss: 0.5649 - val_accuracy: 0.7135\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7535 - val_loss: 0.5627 - val_accuracy: 0.7135\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7552 - val_loss: 0.5606 - val_accuracy: 0.7135\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7569 - val_loss: 0.5585 - val_accuracy: 0.7135\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7604 - val_loss: 0.5566 - val_accuracy: 0.7083\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7639 - val_loss: 0.5548 - val_accuracy: 0.7083\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7656 - val_loss: 0.5531 - val_accuracy: 0.7135\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7708 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.7639 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7639 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.7674 - val_loss: 0.5473 - val_accuracy: 0.7188\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7726 - val_loss: 0.5459 - val_accuracy: 0.7188\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5168 - accuracy: 0.7691 - val_loss: 0.5446 - val_accuracy: 0.7135\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.7674 - val_loss: 0.5435 - val_accuracy: 0.7083\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.7708 - val_loss: 0.5424 - val_accuracy: 0.7135\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7622 - val_loss: 0.5415 - val_accuracy: 0.7135\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7656 - val_loss: 0.5405 - val_accuracy: 0.7135\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7622 - val_loss: 0.5396 - val_accuracy: 0.7135\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7622 - val_loss: 0.5387 - val_accuracy: 0.7135\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7587 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7552 - val_loss: 0.5371 - val_accuracy: 0.7240\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7552 - val_loss: 0.5362 - val_accuracy: 0.7240\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7552 - val_loss: 0.5355 - val_accuracy: 0.7240\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7552 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7569 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7569 - val_loss: 0.5339 - val_accuracy: 0.7240\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7587 - val_loss: 0.5335 - val_accuracy: 0.7292\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7622 - val_loss: 0.5332 - val_accuracy: 0.7292\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7639 - val_loss: 0.5328 - val_accuracy: 0.7292\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7674 - val_loss: 0.5325 - val_accuracy: 0.7292\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.7674 - val_loss: 0.5322 - val_accuracy: 0.7292\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7691 - val_loss: 0.5321 - val_accuracy: 0.7292\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7656 - val_loss: 0.5319 - val_accuracy: 0.7292\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7708 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7656 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7674 - val_loss: 0.5314 - val_accuracy: 0.7240\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.7656 - val_loss: 0.5312 - val_accuracy: 0.7188\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.7674 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7674 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.7674 - val_loss: 0.5305 - val_accuracy: 0.7240\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4844 - accuracy: 0.7674 - val_loss: 0.5303 - val_accuracy: 0.7240\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4837 - accuracy: 0.7622 - val_loss: 0.5299 - val_accuracy: 0.7240\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4829 - accuracy: 0.7639 - val_loss: 0.5296 - val_accuracy: 0.7240\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4821 - accuracy: 0.7639 - val_loss: 0.5294 - val_accuracy: 0.7240\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4812 - accuracy: 0.7622 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.7604 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.7622 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4792 - accuracy: 0.7622 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4787 - accuracy: 0.7639 - val_loss: 0.5282 - val_accuracy: 0.7240\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4780 - accuracy: 0.7622 - val_loss: 0.5279 - val_accuracy: 0.7292\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4773 - accuracy: 0.7639 - val_loss: 0.5277 - val_accuracy: 0.7292\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.5272 - val_accuracy: 0.7292\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7656 - val_loss: 0.5271 - val_accuracy: 0.7344\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7656 - val_loss: 0.5268 - val_accuracy: 0.7344\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4749 - accuracy: 0.7656 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.7656 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.7656 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4736 - accuracy: 0.7639 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7622 - val_loss: 0.5257 - val_accuracy: 0.7344\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7639 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7622 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7622 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7622 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7622 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7622 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7622 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7622 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7622 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7622 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7622 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7622 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7622 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7622 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7639 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7622 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7639 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7639 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7639 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7639 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7622 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7622 - val_loss: 0.5211 - val_accuracy: 0.7448\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7622 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7639 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7656 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7622 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7622 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7639 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7622 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7622 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7622 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7639 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7622 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7622 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7587 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4602 - accuracy: 0.7587 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7604 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7604 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7639 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7639 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7622 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7622 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7604 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7622 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7622 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7622 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7622 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7639 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7622 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7639 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7639 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.7639 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7674 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7656 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7656 - val_loss: 0.5181 - val_accuracy: 0.7448\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4553 - accuracy: 0.7656 - val_loss: 0.5181 - val_accuracy: 0.7448\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7448\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7674 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7691 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7674 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7691 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7708 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7708 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7726 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7691 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7743 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7743 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7708 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7708 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7674 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7708 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7674 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7708 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7708 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7708 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7708 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7726 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7726 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7726 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7708 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7726 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7726 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4487 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7292\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.7708 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4480 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5207 - val_accuracy: 0.7292\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4476 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4476 - accuracy: 0.7726 - val_loss: 0.5205 - val_accuracy: 0.7292\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4474 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4474 - accuracy: 0.7691 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4474 - accuracy: 0.7726 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7778 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7726 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7795 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7726 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7708 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7708 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7726 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7726 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7708 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7743 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7743 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7726 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7726 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7726 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7726 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7760 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7726 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7708 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7726 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7708 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7743 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7691 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7708 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7708 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7708 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7691 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7778 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7760 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7778 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7760 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.7778 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7743 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4378 - accuracy: 0.7778 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7778 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4374 - accuracy: 0.7760 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.7778 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.4373 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4371 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4370 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7448\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7778 - val_loss: 0.5207 - val_accuracy: 0.7448\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7448\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7778 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.7778 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7778 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.5213 - val_accuracy: 0.7396\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5230 - val_accuracy: 0.7396\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.7899 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.7934 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.7917 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7917 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7917 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7917 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.7882 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4254 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4251 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4252 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4251 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5237 - val_accuracy: 0.7344\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4247 - accuracy: 0.7934 - val_loss: 0.5237 - val_accuracy: 0.7344\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4243 - accuracy: 0.7934 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5237 - val_accuracy: 0.7188\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.5237 - val_accuracy: 0.7188\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5236 - val_accuracy: 0.7188\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.5236 - val_accuracy: 0.7188\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5237 - val_accuracy: 0.7188\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.5236 - val_accuracy: 0.7188\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5236 - val_accuracy: 0.7188\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5236 - val_accuracy: 0.7188\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5235 - val_accuracy: 0.7188\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7986 - val_loss: 0.5235 - val_accuracy: 0.7188\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5235 - val_accuracy: 0.7188\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.7986 - val_loss: 0.5234 - val_accuracy: 0.7188\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5234 - val_accuracy: 0.7188\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5235 - val_accuracy: 0.7188\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5235 - val_accuracy: 0.7188\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5235 - val_accuracy: 0.7188\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5234 - val_accuracy: 0.7188\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5234 - val_accuracy: 0.7188\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5234 - val_accuracy: 0.7188\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8038 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8021 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8038 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4174 - accuracy: 0.8021 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4163 - accuracy: 0.8038 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4164 - accuracy: 0.8056 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.8038 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5246 - val_accuracy: 0.7240\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5246 - val_accuracy: 0.7240\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8038 - val_loss: 0.5247 - val_accuracy: 0.7240\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8056 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8056 - val_loss: 0.5249 - val_accuracy: 0.7240\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8073 - val_loss: 0.5249 - val_accuracy: 0.7240\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8038 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.8038 - val_loss: 0.5250 - val_accuracy: 0.7240\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8056 - val_loss: 0.5250 - val_accuracy: 0.7240\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8073 - val_loss: 0.5250 - val_accuracy: 0.7240\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8056 - val_loss: 0.5250 - val_accuracy: 0.7240\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8056 - val_loss: 0.5251 - val_accuracy: 0.7240\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8073 - val_loss: 0.5251 - val_accuracy: 0.7240\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8073 - val_loss: 0.5252 - val_accuracy: 0.7240\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5252 - val_accuracy: 0.7292\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8056 - val_loss: 0.5253 - val_accuracy: 0.7292\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8056 - val_loss: 0.5253 - val_accuracy: 0.7240\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8056 - val_loss: 0.5255 - val_accuracy: 0.7292\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8056 - val_loss: 0.5255 - val_accuracy: 0.7240\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8073 - val_loss: 0.5255 - val_accuracy: 0.7292\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.8056 - val_loss: 0.5256 - val_accuracy: 0.7292\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8056 - val_loss: 0.5258 - val_accuracy: 0.7240\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8056 - val_loss: 0.5257 - val_accuracy: 0.7292\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8073 - val_loss: 0.5258 - val_accuracy: 0.7292\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8073 - val_loss: 0.5259 - val_accuracy: 0.7292\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8038 - val_loss: 0.5260 - val_accuracy: 0.7292\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8073 - val_loss: 0.5262 - val_accuracy: 0.7292\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8073 - val_loss: 0.5263 - val_accuracy: 0.7292\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8038 - val_loss: 0.5263 - val_accuracy: 0.7292\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8056 - val_loss: 0.5263 - val_accuracy: 0.7292\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8056 - val_loss: 0.5265 - val_accuracy: 0.7292\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8056 - val_loss: 0.5265 - val_accuracy: 0.7292\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8073 - val_loss: 0.5266 - val_accuracy: 0.7292\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8056 - val_loss: 0.5267 - val_accuracy: 0.7292\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.5268 - val_accuracy: 0.7292\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.5271 - val_accuracy: 0.7292\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5271 - val_accuracy: 0.7292\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5272 - val_accuracy: 0.7292\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8073 - val_loss: 0.5274 - val_accuracy: 0.7292\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5274 - val_accuracy: 0.7292\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8056 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.5277 - val_accuracy: 0.7292\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5278 - val_accuracy: 0.7292\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.5279 - val_accuracy: 0.7292\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8038 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8056 - val_loss: 0.5282 - val_accuracy: 0.7292\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5282 - val_accuracy: 0.7292\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5283 - val_accuracy: 0.7292\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8038 - val_loss: 0.5284 - val_accuracy: 0.7292\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8038 - val_loss: 0.5284 - val_accuracy: 0.7292\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8038 - val_loss: 0.5284 - val_accuracy: 0.7344\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8038 - val_loss: 0.5285 - val_accuracy: 0.7344\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5285 - val_accuracy: 0.7292\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5286 - val_accuracy: 0.7292\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.5287 - val_accuracy: 0.7292\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8038 - val_loss: 0.5288 - val_accuracy: 0.7292\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5289 - val_accuracy: 0.7292\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8038 - val_loss: 0.5289 - val_accuracy: 0.7292\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.5290 - val_accuracy: 0.7292\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.5293 - val_accuracy: 0.7344\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4131 - accuracy: 0.8003 - val_loss: 0.5293 - val_accuracy: 0.7344\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8056 - val_loss: 0.5293 - val_accuracy: 0.7344\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5294 - val_accuracy: 0.7344\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8038 - val_loss: 0.5295 - val_accuracy: 0.7344\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5296 - val_accuracy: 0.7344\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.5298 - val_accuracy: 0.7344\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4130 - accuracy: 0.8038 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8038 - val_loss: 0.5300 - val_accuracy: 0.7344\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8056 - val_loss: 0.5301 - val_accuracy: 0.7344\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8038 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4129 - accuracy: 0.8056 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4129 - accuracy: 0.8038 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4128 - accuracy: 0.8038 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4127 - accuracy: 0.8038 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4127 - accuracy: 0.8056 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4126 - accuracy: 0.8038 - val_loss: 0.5307 - val_accuracy: 0.7344\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4125 - accuracy: 0.8038 - val_loss: 0.5308 - val_accuracy: 0.7344\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5309 - val_accuracy: 0.7344\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4125 - accuracy: 0.8038 - val_loss: 0.5309 - val_accuracy: 0.7344\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.5310 - val_accuracy: 0.7344\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4124 - accuracy: 0.8056 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4123 - accuracy: 0.8038 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8038 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5317 - val_accuracy: 0.7344\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8038 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8073 - val_loss: 0.5319 - val_accuracy: 0.7344\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5321 - val_accuracy: 0.7344\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5321 - val_accuracy: 0.7344\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5321 - val_accuracy: 0.7344\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8056 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8056 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8090 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8021 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8056 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8056 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8073 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8073 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8056 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8073 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8073 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8038 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8038 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8056 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8073 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8073 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8073 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8073 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8056 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8056 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8073 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8090 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.8090 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8073 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8073 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8090 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4099 - accuracy: 0.8090 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8090 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8090 - val_loss: 0.5313 - val_accuracy: 0.7396\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8090 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8108 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5300 - val_accuracy: 0.7344\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8056 - val_loss: 0.5298 - val_accuracy: 0.7344\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8108 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8108 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5295 - val_accuracy: 0.7344\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5293 - val_accuracy: 0.7344\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8108 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8125 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8125 - val_loss: 0.5288 - val_accuracy: 0.7344\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4082 - accuracy: 0.8142 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4079 - accuracy: 0.8125 - val_loss: 0.5288 - val_accuracy: 0.7344\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4076 - accuracy: 0.8142 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4078 - accuracy: 0.8125 - val_loss: 0.5286 - val_accuracy: 0.7344\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4077 - accuracy: 0.8142 - val_loss: 0.5284 - val_accuracy: 0.7344\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4078 - accuracy: 0.8142 - val_loss: 0.5283 - val_accuracy: 0.7344\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4076 - accuracy: 0.8142 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4074 - accuracy: 0.8125 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4072 - accuracy: 0.8142 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.8125 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4073 - accuracy: 0.8108 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8142 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4072 - accuracy: 0.8142 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5279 - val_accuracy: 0.7344\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4071 - accuracy: 0.8142 - val_loss: 0.5279 - val_accuracy: 0.7344\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.5279 - val_accuracy: 0.7344\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5278 - val_accuracy: 0.7344\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4069 - accuracy: 0.8177 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4067 - accuracy: 0.8177 - val_loss: 0.5283 - val_accuracy: 0.7344\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8142 - val_loss: 0.5283 - val_accuracy: 0.7344\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4067 - accuracy: 0.8160 - val_loss: 0.5285 - val_accuracy: 0.7344\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.5283 - val_accuracy: 0.7344\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8142 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8160 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8142 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7344\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5284 - val_accuracy: 0.7344\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5284 - val_accuracy: 0.7344\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8142 - val_loss: 0.5283 - val_accuracy: 0.7344\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8177 - val_loss: 0.5286 - val_accuracy: 0.7344\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8142 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8160 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7344\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5289 - val_accuracy: 0.7292\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5288 - val_accuracy: 0.7344\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5288 - val_accuracy: 0.7344\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8177 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8160 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8142 - val_loss: 0.5291 - val_accuracy: 0.7292\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8073 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8108 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8090 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5294 - val_accuracy: 0.7344\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5293 - val_accuracy: 0.7344\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5295 - val_accuracy: 0.7344\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8108 - val_loss: 0.5298 - val_accuracy: 0.7344\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5296 - val_accuracy: 0.7344\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5298 - val_accuracy: 0.7344\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.5298 - val_accuracy: 0.7344\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8090 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7344\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8056 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8108 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8108 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4045 - accuracy: 0.8142 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4045 - accuracy: 0.8125 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.8056 - val_loss: 0.5309 - val_accuracy: 0.7344\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.5308 - val_accuracy: 0.7344\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8073 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8142 - val_loss: 0.5309 - val_accuracy: 0.7292\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8090 - val_loss: 0.5308 - val_accuracy: 0.7292\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8073 - val_loss: 0.5308 - val_accuracy: 0.7292\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5308 - val_accuracy: 0.7292\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8073 - val_loss: 0.5309 - val_accuracy: 0.7292\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5309 - val_accuracy: 0.7292\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5309 - val_accuracy: 0.7292\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4040 - accuracy: 0.8073 - val_loss: 0.5312 - val_accuracy: 0.7292\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4039 - accuracy: 0.8142 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5314 - val_accuracy: 0.7292\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7292\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5315 - val_accuracy: 0.7292\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8073 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4037 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7292\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7292\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4037 - accuracy: 0.8073 - val_loss: 0.5318 - val_accuracy: 0.7292\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4039 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7292\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5320 - val_accuracy: 0.7240\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5320 - val_accuracy: 0.7292\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4038 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7292\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5319 - val_accuracy: 0.7240\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5323 - val_accuracy: 0.7240\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4035 - accuracy: 0.8073 - val_loss: 0.5323 - val_accuracy: 0.7240\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5321 - val_accuracy: 0.7240\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4034 - accuracy: 0.8073 - val_loss: 0.5321 - val_accuracy: 0.7292\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4036 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7292\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.5327 - val_accuracy: 0.7292\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5327 - val_accuracy: 0.7292\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4035 - accuracy: 0.8073 - val_loss: 0.5327 - val_accuracy: 0.7240\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4038 - accuracy: 0.8125 - val_loss: 0.5326 - val_accuracy: 0.7292\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5326 - val_accuracy: 0.7292\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5330 - val_accuracy: 0.7240\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8142 - val_loss: 0.5333 - val_accuracy: 0.7240\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8073 - val_loss: 0.5332 - val_accuracy: 0.7240\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5331 - val_accuracy: 0.7240\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5330 - val_accuracy: 0.7240\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5334 - val_accuracy: 0.7240\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5332 - val_accuracy: 0.7240\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5331 - val_accuracy: 0.7240\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8142 - val_loss: 0.5332 - val_accuracy: 0.7240\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5332 - val_accuracy: 0.7240\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5332 - val_accuracy: 0.7292\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8125 - val_loss: 0.5335 - val_accuracy: 0.7292\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5333 - val_accuracy: 0.7240\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5337 - val_accuracy: 0.7240\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4032 - accuracy: 0.8073 - val_loss: 0.5336 - val_accuracy: 0.7240\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5336 - val_accuracy: 0.7240\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8073 - val_loss: 0.5335 - val_accuracy: 0.7240\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8160 - val_loss: 0.5334 - val_accuracy: 0.7240\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.5334 - val_accuracy: 0.7292\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5338 - val_accuracy: 0.7240\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8142 - val_loss: 0.5337 - val_accuracy: 0.7240\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8073 - val_loss: 0.5342 - val_accuracy: 0.7240\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4029 - accuracy: 0.8108 - val_loss: 0.5341 - val_accuracy: 0.7240\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.5340 - val_accuracy: 0.7240\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8125 - val_loss: 0.5339 - val_accuracy: 0.7240\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8125 - val_loss: 0.5342 - val_accuracy: 0.7240\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8073 - val_loss: 0.5342 - val_accuracy: 0.7240\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8073 - val_loss: 0.5345 - val_accuracy: 0.7188\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8194 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8125 - val_loss: 0.5343 - val_accuracy: 0.7188\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5343 - val_accuracy: 0.7240\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8125 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4028 - accuracy: 0.8142 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8125 - val_loss: 0.5343 - val_accuracy: 0.7240\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8142 - val_loss: 0.5346 - val_accuracy: 0.7240\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8142 - val_loss: 0.5343 - val_accuracy: 0.7240\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8125 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4026 - accuracy: 0.8142 - val_loss: 0.5342 - val_accuracy: 0.7188\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8142 - val_loss: 0.5346 - val_accuracy: 0.7188\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8142 - val_loss: 0.5346 - val_accuracy: 0.7188\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4028 - accuracy: 0.8125 - val_loss: 0.5344 - val_accuracy: 0.7188\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.5347 - val_accuracy: 0.7188\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8142 - val_loss: 0.5347 - val_accuracy: 0.7188\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8125 - val_loss: 0.5351 - val_accuracy: 0.7188\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8142 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4025 - accuracy: 0.8125 - val_loss: 0.5352 - val_accuracy: 0.7240\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8142 - val_loss: 0.5351 - val_accuracy: 0.7240\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4027 - accuracy: 0.8142 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8160 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8160 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8125 - val_loss: 0.5353 - val_accuracy: 0.7188\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8125 - val_loss: 0.5354 - val_accuracy: 0.7240\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4024 - accuracy: 0.8160 - val_loss: 0.5353 - val_accuracy: 0.7188\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8125 - val_loss: 0.5352 - val_accuracy: 0.7188\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5352 - val_accuracy: 0.7188\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8142 - val_loss: 0.5354 - val_accuracy: 0.7188\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4019 - accuracy: 0.8194 - val_loss: 0.5357 - val_accuracy: 0.7188\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8142 - val_loss: 0.5356 - val_accuracy: 0.7240\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8142 - val_loss: 0.5355 - val_accuracy: 0.7188\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8142 - val_loss: 0.5357 - val_accuracy: 0.7240\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8142 - val_loss: 0.5356 - val_accuracy: 0.7188\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8160 - val_loss: 0.5356 - val_accuracy: 0.7240\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8125 - val_loss: 0.5355 - val_accuracy: 0.7188\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8142 - val_loss: 0.5356 - val_accuracy: 0.7188\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5359 - val_accuracy: 0.7188\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8125 - val_loss: 0.5360 - val_accuracy: 0.7188\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8108 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8194 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5360 - val_accuracy: 0.7240\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5360 - val_accuracy: 0.7240\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4019 - accuracy: 0.8125 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8160 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8125 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4022 - accuracy: 0.8142 - val_loss: 0.5366 - val_accuracy: 0.7188\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4017 - accuracy: 0.8108 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5362 - val_accuracy: 0.7188\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4019 - accuracy: 0.8160 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5366 - val_accuracy: 0.7188\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5368 - val_accuracy: 0.7188\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8160 - val_loss: 0.5367 - val_accuracy: 0.7188\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4019 - accuracy: 0.8108 - val_loss: 0.5366 - val_accuracy: 0.7188\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5369 - val_accuracy: 0.7188\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4020 - accuracy: 0.8160 - val_loss: 0.5368 - val_accuracy: 0.7188\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8177 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4022 - accuracy: 0.8177 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4022 - accuracy: 0.8125 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.8142 - val_loss: 0.5373 - val_accuracy: 0.7188\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8177 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4022 - accuracy: 0.8160 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4016 - accuracy: 0.8160 - val_loss: 0.5368 - val_accuracy: 0.7188\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8142 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5374 - val_accuracy: 0.7188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the results of training and validation loss using different learning rates, number of epochs and network structures\n",
        "run_hist_1.history.keys()\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "mRoVYVe2qExy",
        "outputId": "374e8db7-cc29-4df8-a7de-769e4c826420"
      },
      "id": "mRoVYVe2qExy",
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cc990dacc70>"
            ]
          },
          "metadata": {},
          "execution_count": 168
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpret your result:\n",
        "My interpretation towards the result of my chosen different learning rates and number of epoch shows that the model doesnt have much notable changes towards the train loss and validation loss."
      ],
      "metadata": {
        "id": "Ewwfx9CgqRG2"
      },
      "id": "Ewwfx9CgqRG2"
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "in Conclusion this activity has helped me understand on the different learning models and training neural networks wherein i also learn to distinguish and interpret the results of the models and whenever the model is accurate in representing the data and variables."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}